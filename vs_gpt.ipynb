{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPYrkwFyLW9RZtWK7pyGY0G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vineetsarpal/vs-gpt/blob/main/vs_gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VSGPT: AI-Powered Guitar Pro Tab Generation"
      ],
      "metadata": {
        "id": "Xzi5l5KDXNaL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "621a38a9"
      },
      "source": [
        "## Project Summary\n",
        "\n",
        "This project demonstrates the creation of a Guitar Pro tab generation model using PyTorch and the DadaGP library. The core idea is to train a sequence-to-sequence model on existing Guitar Pro files, allowing it to learn musical patterns and generate new, stylistically similar tabs.\n",
        "\n",
        "**Key Steps Involved:**\n",
        "\n",
        "1.  **Data Preparation:** Guitar Pro (.gp) files are processed using the `dadagp.py` encoder to convert musical notation into a sequence of tokens (e.g., `tempo:120`, `note:s6:f-2`, `nfx:hammer`). These tokens represent various musical events, including notes, rests, techniques, and structural elements.\n",
        "2.  **Vocabulary Building:** A unique vocabulary of all encountered tokens is built, and each token is mapped to a numerical ID. Special tokens like `<pad>` and `<unk>` are included for padding sequences and handling unknown tokens, respectively.\n",
        "3.  **Dataset Creation:** Token sequences are prepared into a format suitable for sequence modeling, where the model learns to predict the next token based on previous tokens.\n",
        "4.  **Model Definition (`VSGPTModel`):** An LSTM-based neural network is defined. It includes an embedding layer to convert token IDs into dense vectors, LSTM layers to capture sequential dependencies, and a linear output layer to predict the probability distribution over the next token in the vocabulary.\n",
        "5.  **Model Training:** The model is trained using a standard language modeling objective (CrossEntropyLoss), optimizing its parameters to minimize the difference between predicted and actual next tokens. Training progress is monitored, and the best-performing model is saved.\n",
        "6.  **Tab Generation:** Once trained, the model can generate new musical sequences by taking a prompt (e.g., `artist:vineet sarpal`, `tempo:120`, `start`) and iteratively predicting subsequent tokens. Techniques like temperature and top-k sampling are used to add creativity and coherence to the generation.\n",
        "7.  **Decoding to Guitar Pro:** The generated token sequences are then passed to the `dadagp.py` decoder, which converts them back into playable Guitar Pro (.gp5) files, thus realizing the AI-generated music.\n",
        "8.  **Output Management:** All generated tabs and saved model checkpoints are stored in a designated `outputs` and `models` directory on Google Drive for persistence.\n",
        "\n",
        "This project provides a complete pipeline from raw Guitar Pro files to a trained generative model, capable of composing new musical pieces in a learned style."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Mount Google Drive and Setup Directories"
      ],
      "metadata": {
        "id": "QLDJnchpXEeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== MOUNT GOOGLE DRIVE & PROJECT FOLDERS ====\n",
        "from google.colab import drive\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BASE_DIR = userdata.get('BASE_DIR') # set in secrets\n",
        "TABS_DIR = os.path.join(BASE_DIR, 'tabs')\n",
        "TOKENS_DIR = os.path.join(BASE_DIR, 'tokens')\n",
        "MODELS_DIR = os.path.join(BASE_DIR, 'models')\n",
        "OUT_DIR = os.path.join(BASE_DIR, 'outputs')\n",
        "\n",
        "os.makedirs(TABS_DIR, exist_ok=True)\n",
        "os.makedirs(TOKENS_DIR, exist_ok=True)\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Base dir:\", BASE_DIR)\n",
        "print(\"Put your .gp files in:\", TABS_DIR)"
      ],
      "metadata": {
        "id": "TP1VLsmTbWlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Preparation"
      ],
      "metadata": {
        "id": "pV6kVLLmev2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== DISCOVER YOUR GUITAR PRO FILES ====\n",
        "import glob\n",
        "\n",
        "gp_files = sorted(glob.glob(TABS_DIR + '/*.gp*'))\n",
        "print(\"Found\", len(gp_files), \"tabs:\")\n",
        "for f in gp_files:\n",
        "    print(\" -\", os.path.basename(f))"
      ],
      "metadata": {
        "id": "pz6bEQFheOAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CUSTOM TOKENIZER FOR GUITAR PRO ====\n",
        "#import guitarpro\n",
        "\n",
        "\n",
        "# song = guitarpro.parse(gp_files[0])\n",
        "# print(f\"Looking at file: \", gp_files[0])\n",
        "# tokens = []\n",
        "\n",
        "# tokens.append('artist:vineet sarpal')\n",
        "# tokens.append(f\"tempo:{song.tempo}\")\n",
        "# tokens.append('start')\n",
        "\n",
        "# # use first track (or tweak to select solo/lead)\n",
        "# print(f\"Song: \", song.artist)\n",
        "# track = song.tracks[0]\n",
        "\n",
        "# for track in song.tracks:\n",
        "#   print(f\"Track: \",track.strings)\n",
        "#   for measure in track.measures:\n",
        "#     for voice in measure.voices:\n",
        "#       for beat in voice.beats:\n",
        "#         for note in beat.notes:\n",
        "#           tokens.append(f\"note:{note}\")\n",
        "#           print(f\"note:{note.value}, string:{note.string}\")\n"
      ],
      "metadata": {
        "id": "UDxqpQgmeQRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== SETUP DADAGP ENCODER ====\n",
        "!wget https://raw.githubusercontent.com/dada-bots/dadaGP/main/dadagp.py -O /content/dadagp.py\n",
        "!wget https://raw.githubusercontent.com/dada-bots/dadaGP/main/token_splitter.py -O /content/token_splitter.py\n",
        "!wget https://raw.githubusercontent.com/dada-bots/dadaGP/main/blank.gp5 -O /content/blank.gp5\n",
        "!pip install \"PyGuitarPro==0.6\" --quiet\n",
        "import subprocess, os\n",
        "\n",
        "def encode_tab(gp_file):\n",
        "    \"\"\"Use DadaGP encoder to encode Guitar Pro tabs\"\"\"\n",
        "    base_name = os.path.splitext(os.path.basename(gp_file))[0]\n",
        "    tokens_file = os.path.join(TOKENS_DIR, f\"{base_name}.tokens.txt\")\n",
        "    cmd = ['python', '/content/dadagp.py', 'encode', gp_file, tokens_file, 'vineet sarpal']\n",
        "\n",
        "    result = subprocess.run(cmd, capture_output=True)\n",
        "    if result.returncode == 0:\n",
        "        with open(tokens_file, 'r') as f:\n",
        "            tokens = f.read().strip().split()\n",
        "        print(f\"‚úÖ Encoded {os.path.basename(gp_file)} ‚Üí {tokens_file}\")\n",
        "        print(f\"   {len(tokens)} tokens\")\n",
        "        return tokens\n",
        "    else:\n",
        "        print(f\"‚ùå Failed to encode {os.path.basename(gp_file)}:\")\n",
        "        print(f\"   {result.stderr}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "hKmN1YWQ6Wh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== ENCODE AND TOKENIZE YOUR GUITAR PRO FILES ====#\n",
        "all_sequences = []\n",
        "for gp_file in gp_files:\n",
        "    tokens = encode_tab(gp_file)\n",
        "    all_sequences.extend([tokens[i:i+512] for i in range(0, len(tokens)-512, 256)])\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(all_sequences)} sequences!\")"
      ],
      "metadata": {
        "id": "YOYdE2p5BD6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Build Vocabulary"
      ],
      "metadata": {
        "id": "diIUo1tBe8Pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== BUILD VOCABULARY ====\n",
        "from collections import Counter\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "# Flatten all sequences to count tokens\n",
        "all_tokens_flat = []\n",
        "for seq in all_sequences:\n",
        "    all_tokens_flat.extend(seq)\n",
        "\n",
        "token_counts = Counter(all_tokens_flat)\n",
        "vocab = ['<pad>', '<unk>'] + sorted(token_counts.keys())  # Add special tokens\n",
        "token_to_id = {token: idx for idx, token in enumerate(vocab)}\n",
        "id_to_token = {idx: token for token, idx in token_to_id.items()}\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "print(f\"‚úÖ Vocab built: {vocab_size} tokens\")\n",
        "print(\"Most common:\", token_counts.most_common(10))\n"
      ],
      "metadata": {
        "id": "U2VQSiE7UEhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Create Dataset"
      ],
      "metadata": {
        "id": "628onzcTe_tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CREATE DATASET ====\n",
        "MAX_SEQ_LEN = 512\n",
        "\n",
        "class TabDataset(Dataset):\n",
        "    def __init__(self, sequences, token_to_id, max_len=MAX_SEQ_LEN):\n",
        "        self.sequences = []\n",
        "        for seq in sequences:\n",
        "            # Convert to IDs\n",
        "            ids = [token_to_id.get(t, token_to_id['<unk>']) for t in seq]\n",
        "            if len(ids) >= 2:  # Need at least 2 tokens\n",
        "                self.sequences.append(torch.tensor(ids, dtype=torch.long))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.sequences[idx]\n",
        "        x = seq[:-1]  # input: all but last token\n",
        "        y = seq[1:]   # target: all but first token (shifted)\n",
        "        return x, y\n",
        "\n",
        "dataset = TabDataset(all_sequences, token_to_id)\n",
        "train_loader = DataLoader(dataset, batch_size=4, shuffle=True, drop_last=True)  # Small batch for Colab\n",
        "\n",
        "print(f\"‚úÖ Dataset ready: {len(dataset)} sequences\")\n"
      ],
      "metadata": {
        "id": "Em6cPwLrlVfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Define Model Architecture"
      ],
      "metadata": {
        "id": "aHTamYAfefSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== DEFINE MODEL ====\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "class VSGPTModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=2,\n",
        "                           batch_first=True, dropout=0.3)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        logits = self.fc(lstm_out)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "VCtsYoTzlk0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VSGPTModel(vocab_size).to(device)\n",
        "print(f\"‚úÖ Model created: {sum(p.numel() for p in model.parameters())} parameters\")"
      ],
      "metadata": {
        "id": "scUgphXXmo5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.   Train Model"
      ],
      "metadata": {
        "id": "ZKpmpmPMfQyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== TRAIN MODEL ====\n",
        "# Training setup\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token_to_id['<pad>'])\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5)\n",
        "\n",
        "EPOCHS = 50\n",
        "best_loss = float('inf')\n",
        "\n",
        "print(\"üöÄ Training model...\")\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, (x, y) in enumerate(train_loader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits.reshape(-1, vocab_size), y.reshape(-1))\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    scheduler.step(avg_loss)\n",
        "\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        # Save best model to Drive\n",
        "        torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'token_to_id': token_to_id,\n",
        "            'id_to_token': id_to_token,\n",
        "            'vocab_size': vocab_size\n",
        "        }, os.path.join(MODELS_DIR, 'vs_gpt_best.pt'))\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d}/{EPOCHS} | Loss: {avg_loss:.4f} | LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "print(\"‚úÖ Training complete! Best model saved.\")\n"
      ],
      "metadata": {
        "id": "59jnjk2Gl03k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Generate and Decode Tabs"
      ],
      "metadata": {
        "id": "wbMIsL_ZfVGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== GENERATE NEW TABS ====\n",
        "def generate_tabs(model, prompt_tokens, max_new=256, temperature=0.8, top_k=50):\n",
        "    \"\"\"Generate new guitar tabs from your style\"\"\"\n",
        "    model.eval()\n",
        "    ids = [token_to_id.get(t, token_to_id['<unk>']) for t in prompt_tokens]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_new):\n",
        "            # Use last 256 tokens as context\n",
        "            context = torch.tensor([ids[-256:]], device=device)\n",
        "            logits = model(context)[:, -1, :] / temperature\n",
        "\n",
        "            # Top-K sampling\n",
        "            top_k_logits, top_k_ids = torch.topk(logits, top_k)\n",
        "            probs = torch.softmax(top_k_logits, dim=-1)\n",
        "            next_id = top_k_ids[0][torch.multinomial(probs[0], 1)].item()\n",
        "\n",
        "            ids.append(next_id)\n",
        "\n",
        "            # Stop conditions\n",
        "            if id_to_token[next_id] in ['end', 'end_of_song']:\n",
        "                break\n",
        "\n",
        "    return [id_to_token[i] for i in ids]"
      ],
      "metadata": {
        "id": "rGWmPzoapTZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test generation!\n",
        "prompt = ['vineet', 'sarpal', 'downtune:-2', 'tempo:120', 'start']\n",
        "generated_tokens = generate_tabs(model, prompt, max_new=1024, temperature=0.85)\n",
        "\n",
        "print(\"\\nüé∏ GENERATED TAB (first 50 tokens):\")\n",
        "print(\" \".join(generated_tokens[:50]))\n",
        "print(f\"\\nTotal length: {len(generated_tokens)} tokens\")"
      ],
      "metadata": {
        "id": "l9Z8YdqgnKr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== TEMP SAVE GENERATED TOKENS ====\n",
        "# Save generated tokens to a temp file\n",
        "generated_tokens_file = '/content/generated_song.tokens.txt'\n",
        "with open(generated_tokens_file, 'w') as f:\n",
        "    f.write(\" \".join(generated_tokens))\n",
        "\n",
        "print(f\"‚úÖ Saved tokens to {generated_tokens_file}\")"
      ],
      "metadata": {
        "id": "p6lgkdJxoKp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== DECODE TOKENS TO GP FILES ====\n",
        "def decode_to_guitarpro(tokens_file, output_gp_file):\n",
        "    \"\"\"Convert tokens back to Guitar Pro using DadaGP decoder\"\"\"\n",
        "    import subprocess\n",
        "\n",
        "    cmd = ['python', '/content/dadagp.py', 'decode', tokens_file, output_gp_file]\n",
        "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "    if result.returncode == 0:\n",
        "        print(f\"‚úÖ Decoded {tokens_file} ‚Üí {output_gp_file}\")\n",
        "        return output_gp_file\n",
        "    else:\n",
        "        print(f\"‚ùå Decode failed:\")\n",
        "        print(result.stderr)\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "5qB8Noh-oWc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and decode\n",
        "output_gp = '/content/generated_tab.gp5'\n",
        "decoded_file = decode_to_guitarpro(generated_tokens_file, output_gp)\n",
        "\n",
        "if decoded_file:\n",
        "    print(f\"üé∏ PLAYABLE TAB CREATED: {decoded_file}\")"
      ],
      "metadata": {
        "id": "gvMzh36XnRXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== SAVE GENERATED TABS ====\n",
        "# Copy to your project folder\n",
        "drive_output = os.path.join(OUT_DIR, 'song_1.gp5')\n",
        "!cp {output_gp} {drive_output}\n",
        "print(f\"‚úÖ Saved to Drive: {drive_output}\")"
      ],
      "metadata": {
        "id": "aj3L2fecodO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETE: Generate ‚Üí Decode ‚Üí Save\n",
        "def generate_and_decode(model, prompt, output_name=\"generated_tab\", max_new=1024):\n",
        "    \"\"\"Full pipeline: tokens ‚Üí Guitar Pro ‚Üí Drive\"\"\"\n",
        "\n",
        "    # Generate\n",
        "    tokens = generate_tabs(model, prompt, max_new=max_new, temperature=0.85)\n",
        "    temp_tokens = '/content/temp.tokens.txt'\n",
        "\n",
        "    with open(temp_tokens, 'w') as f:\n",
        "        f.write(\"\\n\".join(tokens)) # Changed to join with newlines\n",
        "\n",
        "    # Decode\n",
        "    temp_gp = '/content/temp.gp5'\n",
        "    decoded = decode_to_guitarpro(temp_tokens, temp_gp)\n",
        "\n",
        "    if decoded:\n",
        "        # Save to Drive\n",
        "        final_gp = os.path.join(OUT_DIR, f\"{output_name}.gp5\")\n",
        "        import shutil\n",
        "        shutil.copy(temp_gp, final_gp)\n",
        "        print(f\"üéµ CREATED: {final_gp}\")\n",
        "        print(f\"Tokens: {len(tokens)} | Techniques: {sum(1 for t in tokens if 'nfx' in t)}\")\n",
        "        return final_gp\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "Z9wAJYtwojqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 3 variations\n",
        "prompts = [\n",
        "    ['artist:vineet sarpal', 'tempo:120', 'start'],\n",
        "    ['artist:vineet sarpal', 'tempo:140', 'downtune:0', 'start'],\n",
        "    ['artist:vineet sarpal', 'tempo:100', 'start']\n",
        "]\n",
        "\n",
        "for i, prompt in enumerate(prompts):\n",
        "    generate_and_decode(model, prompt, f\"vs_gpt_variation_{i+1}\")"
      ],
      "metadata": {
        "id": "s-a-LJpgoFsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Save Model"
      ],
      "metadata": {
        "id": "IJb9GP2ufkTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== SAVE MODEL ====\n",
        "# Save final model + full workspace\n",
        "model_path = os.path.join(MODELS_DIR, 'vs_gpt_complete.pt')\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'token_to_id': token_to_id,\n",
        "    'id_to_token': id_to_token,\n",
        "    'all_sequences': all_sequences  # Your original data\n",
        "}, model_path)\n",
        "\n",
        "print(\"‚úÖ Everything saved to Drive!\")\n",
        "print(\"\\nNext time, load with:\")\n",
        "print(f\"checkpoint = torch.load('{model_path}')\")\n"
      ],
      "metadata": {
        "id": "VtlHSDlZmO44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================================= #"
      ],
      "metadata": {
        "id": "T1RVepZukfAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### NOTE: If you have already trained your model and saved the checkpoint, you do not need to re-run the entire training pipeline.\n",
        "\n",
        " Follow these steps to set up your environment, load the model, and generate new tabs:\n",
        "\n",
        "* Mount Google Drive and Setup Directories\n",
        "* Setup DadaGP Encoder\n",
        "* Define Model Architecture\n",
        "* Define Generation Function\n",
        "* Define Decoding Function\n",
        "* Define Complete Generate & Decode Pipeline\n",
        "* Load the Trained Model and Vocabulary\n",
        "* Generate New Tabs"
      ],
      "metadata": {
        "id": "UiLdIgBejk44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Load Model"
      ],
      "metadata": {
        "id": "PVy95TPXialo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the checkpoint\n",
        "print(f\"Loading model from: {MODELS_DIR}\")\n",
        "model_path = os.path.join(MODELS_DIR, 'vs_gpt_complete.pt')\n",
        "checkpoint = torch.load(model_path, map_location=device)\n",
        "\n",
        "# Reconstruct necessary components from the checkpoint\n",
        "loaded_token_to_id = checkpoint['token_to_id']\n",
        "loaded_id_to_token = checkpoint['id_to_token']\n",
        "loaded_vocab_size = len(loaded_token_to_id)\n",
        "\n",
        "# Instantiate the model architecture\n",
        "loaded_model = VSGPTModel(loaded_vocab_size).to(device)\n",
        "\n",
        "# Load the model state dictionary\n",
        "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "loaded_model.eval() # Set the model to evaluation mode\n",
        "\n",
        "\n",
        "print(\"‚úÖ Model loaded successfully!\")\n",
        "print(f\"Loaded model has {sum(p.numel() for p in loaded_model.parameters())} parameters\")\n",
        "\n",
        "# Set the global variables\n",
        "token_to_id = loaded_token_to_id\n",
        "id_to_token = loaded_id_to_token\n",
        "vocab_size = loaded_vocab_size\n",
        "\n",
        "print(\"‚úÖ Global variables updated successfully!\")"
      ],
      "metadata": {
        "id": "FZkI5GGagw34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Generate New Tabs"
      ],
      "metadata": {
        "id": "fh-Rbfwuj4jN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nGenerating a new tab using the loaded model...\")\n",
        "new_prompt = ['artist:vineet sarpal', 'downtune:-2', 'tempo:120', 'start']\n",
        "generate_and_decode(loaded_model, new_prompt, max_new=1024)"
      ],
      "metadata": {
        "id": "C8wU8RuIkrcB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}